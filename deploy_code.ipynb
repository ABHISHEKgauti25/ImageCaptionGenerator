{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfwZDLNoEYbKnCHb/X+2YU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ABHISHEKgauti25/ImageCaptionGenerator/blob/main/deploy_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPLMHl8e2zGG"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok==4.1.1"
      ],
      "metadata": {
        "id": "QTMXnHYE3iTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import cv2\n",
        "from PIL import Image,ImageOps\n",
        "import numpy as np\n",
        "\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "@st.cache_resource\n",
        "def decorder_model():\n",
        "    model = load_model('/content/model.h5')\n",
        "    return model\n",
        "\n",
        "@st.cache_resource\n",
        "def load_tokenizer():\n",
        "    with open('/content/tokenizer.pickle', 'rb') as handle:\n",
        "      tokenizer = pickle.load(handle)\n",
        "    return tokenizer\n",
        "\n",
        "@st.cache_resource\n",
        "def load_vgg():\n",
        "    vgg_model = VGG16()\n",
        "    vgg_model = Model(inputs = vgg_model.inputs, outputs = vgg_model.layers[-2].output)\n",
        "    return vgg_model\n",
        "\n",
        "st.write(\"\"\"\n",
        "        # Image Caption Generator\n",
        "        \"\"\")\n",
        "\n",
        "#loading models and tokenizer\n",
        "model = decorder_model()\n",
        "vgg_model = load_vgg()\n",
        "tokenizer = load_tokenizer()\n",
        "\n",
        "file = st.file_uploader(\"Please upload an Image to generate caption\", type = ['jpg', 'png', 'jpeg'])\n",
        "\n",
        "\n",
        "def generate_features(model, image_data):\n",
        "    target_size = (224, 224)\n",
        "    image = ImageOps.fit(image_data, target_size, Image.ANTIALIAS)\n",
        "    img_array = np.asarray(image)\n",
        "    image_reshaped = img_array[np.newaxis,...]\n",
        "    features = model.predict(image_reshaped)\n",
        "    return features\n",
        "\n",
        "def idx_to_word(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "def pred_caption(img_feature, model, tokenizer):\n",
        "    in_text = 'startseq'\n",
        "    max_length = 35\n",
        "    # iterate over the max length of sequence\n",
        "    for i in range(max_length):\n",
        "        # encode input sequence\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        # pad the sequence\n",
        "        sequence = pad_sequences([sequence], max_length)\n",
        "        # predict next word\n",
        "        yhat = model.predict([img_feature, sequence], verbose=0)\n",
        "        # get index with high probability\n",
        "        yhat = np.argmax(yhat)\n",
        "        # convert index to word\n",
        "        word = idx_to_word(yhat, tokenizer)\n",
        "        # stop if word not found\n",
        "        if word is None:\n",
        "            break\n",
        "        # append word as input for generating next word\n",
        "        in_text += \" \" + word\n",
        "        # stop if we reach end tag\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "\n",
        "    return in_text\n",
        "\n",
        "def remove_start_end_tokens(raw_caption):\n",
        "    words = raw_caption.split()\n",
        "    words = words[1:-1]\n",
        "    sentence = \" \".join([ str(elm) for elm in words])\n",
        "    return sentence\n",
        "\n",
        "if file is None:\n",
        "    st.text(\"No Image selected\")\n",
        "else:\n",
        "    image = Image.open(file)\n",
        "    #displaying image\n",
        "    st.image(image, use_column_width = True)\n",
        "    feature = generate_features(vgg_model, image)\n",
        "    predicted_caption = pred_caption(feature, model, tokenizer)\n",
        "    predicted_caption = remove_start_end_tokens(predicted_caption)\n",
        "    st.success(predicted_caption)\n",
        "    st.text(\"The caption generated might not be fully convincing but hey!! nobody is perfect:-\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEQ-2NtL3RwT",
        "outputId": "cd90fc67-faf5-4de4-e4d3-ba08a2b23f90"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "!ngrok authtoken 2RtDaVIzbeK2bG274aZvm4PPfi7_6K14eBKpwECg3tYoNM2Ms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB6oNYjX3no8",
        "outputId": "0bc2e8e5-d57a-44c2-9115-864ad9a46fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O13pzJ1i3uHg",
        "outputId": "9d99a758-cdbf-4eae-ce83-fab158db0054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok"
      ],
      "metadata": {
        "id": "IbN-sdZmMand"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app_url = ngrok.connect(port  = 8501)\n",
        "app_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JaFRoy6IMslH",
        "outputId": "35b48871-af6c-47cf-8fec-cad03b3a5cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://139b-35-196-113-13.ngrok-free.app'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-VF-QA7N_Quh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}